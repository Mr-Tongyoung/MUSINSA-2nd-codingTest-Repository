# 프로덕션 아키텍처 전환 분석

> 현재 과제용 아키텍처를 실제 대학교 수강신청 서비스로 전환할 때 필요한 변경사항을 분석한다.
> **대학교 도메인의 비용 제약**을 고려하여, 단일 서버에서 최대한 성능을 끌어올리는 전략을 중심으로 다룬다.

---

## 1. 실제 수강신청 트래픽 특성

### 1.1 트래픽 규모

대학교 수강신청은 전형적인 **스파이크 트래픽** 시나리오다. 수천~수만 명의 학생이 오전 9시 또는 10시 정각에 동시 접속한다.

| 항목 | 규모 |
|------|------|
| 대형 대학교 재학생 수 | 20,000~30,000명 |
| 학년별 분산 시 동시 접속자 | 5,000~8,000명 |
| 피크 TPS (전체 요청) | 25,000~50,000 req/s |
| 피크 TPS (수강신청 쓰기) | 2,000~10,000 TPS |
| 극심한 피크 지속 시간 | 30초~60초 |
| 전체 피크 지속 시간 | 3~10분 |

### 1.2 실제 장애 사례

| 대학교 | 사례 |
|--------|------|
| **서울대** | 장바구니 시스템 도입 시 서버 과부하로 수강신청 일정 **2회 연기** |
| **고려대 (2020)** | 수강신청 당일 DDoS 공격으로 전체 등록 **롤백 및 일정 연기** |
| **경상대 (2023)** | 로그인 실패, 버튼 비활성화, 강제 로그아웃 등 **30분~1시간 장애** |
| **성균관대** | 순간 과부하로 약 **20초간 서버 처리 지연** 공식 확인 |

### 1.3 대학교들의 대응 전략

| 전략 | 설명 |
|------|------|
| 학년별 시차 배정 | 월=4학년, 화=3학년 등 분산 |
| 홀짝 학번 분리 | 홀수 학번 Day1, 짝수 Day1 |
| 장바구니(사전 담기) | 신청 전 미리 과목 선택 |
| 마일리지 제도 | 포인트 배분 → 높은 순서대로 배정 (연세대) |

### 1.4 왜 단일 서버 최적화인가?

대학교는 IT 기업이 아니다. 수강신청은 **학기에 2~3회, 각 3~10분** 발생하는 이벤트다.

| 구분 | 다중 서버 (Kubernetes + Kafka + Redis Cluster) | 단일 서버 최적화 |
|------|:--------------------------------------------:|:--------------:|
| 인프라 비용 | 월 수백만 원 (상시 운영) | 서버 1대 유지비 |
| 운영 인력 | DevOps 전담 필요 | 기존 전산팀으로 충분 |
| 복잡도 | 높음 (분산 시스템 운영) | 낮음 (단일 프로세스) |
| 활용률 | 연간 99% 시간 유휴 | 서버 자원 상시 활용 |
| 장애 대응 | 분산 시스템 디버깅 난이도 높음 | 단일 서버 로그 확인으로 충분 |

**연간 1시간도 안 되는 피크를 위해 상시 분산 인프라를 운영하는 것은 과도한 투자다.** 단일 서버의 성능을 극한까지 끌어올리고, 트래픽 유입을 제어하는 것이 대학교 도메인에 현실적인 전략이다.

---

## 2. 현재 아키텍처 vs 프로덕션 아키텍처

### 2.1 전체 구조 비교

**현재 (과제)**:

```
사용자 → Spring Boot (단일 서버) → H2 인메모리 DB
```

**프로덕션 (단일 서버 최적화)**:

```
사용자 → Nginx (리버스 프록시, Rate Limiting, 정적 자산 서빙)
      → Spring Boot (단일 서버)
            ├── Caffeine (Local Cache)
            ├── HikariCP (Connection Pool 최적화)
            ├── Resilience4j (Circuit Breaker, Rate Limiter)
            └── Spring Security + JWT (인증)
      → MySQL/PostgreSQL (단일 인스턴스)
      → Redis (단일 인스턴스, 대기열 + 세션 + 캐시)
```

### 2.2 컴포넌트별 변경사항

| 영역 | 현재 (과제) | 프로덕션 (단일 서버) | 변경 이유 |
|------|------------|-------------------|----------|
| **DB** | H2 인메모리 | MySQL/PostgreSQL (단일) | 영속성, Named Lock 지원, 데드락 자동 감지 |
| **동시성 제어** | JPA 비관적 락 | JPA 비관적 락 유지 + Named Lock 병행 | 단일 서버이므로 DB 락으로 충분 |
| **캐싱** | 없음 | Caffeine (Local Cache) | 추가 인프라 없이 DB 부하 대폭 감소 |
| **인증** | 없음 (공개 API) | Spring Security + JWT | 보안 확보, 사용자 식별 |
| **트래픽 제어** | 없음 | Nginx Rate Limiting + 대기열 페이지 | 서버 과부하 방지 |
| **Rate Limiting** | 없음 | Resilience4j `@RateLimiter` | 사용자당 요청 제한 |
| **에러 처리** | GlobalExceptionHandler | + Circuit Breaker (Resilience4j) | DB 과부하 시 빠른 실패 |
| **커넥션 풀** | HikariCP 기본값 | HikariCP 튜닝 | 커넥션 효율 극대화 |
| **리버스 프록시** | 없음 | Nginx | 정적 자산 분리, 커넥션 관리, Rate Limit |
| **모니터링** | 없음 | Spring Actuator + Prometheus + Grafana | 장애 감지, 성능 분석 |

---

## 3. 핵심 변경사항 상세 분석

### 3.1 데이터베이스: H2 → MySQL/PostgreSQL (단일 인스턴스)

**현재의 한계**:
- 서버 재시작 시 데이터 소실
- Named Lock 미지원
- 데드락 자동 감지 없음 (타임아웃 방식)

**프로덕션 구성 (단일 DB)**:

```
Spring Boot → MySQL 8.0 (단일 인스턴스)
              ├── InnoDB 버퍼 풀 최적화
              ├── 데드락 자동 감지
              ├── Named Lock 사용 가능
              └── 일일 백업 (mysqldump 또는 binlog)
```

Read Replica를 두지 않는다. 단일 서버 환경에서 같은 머신의 Replica는 의미가 없고, 별도 서버 Replica는 비용 대비 효과가 낮다. 대신 **캐싱으로 읽기 부하를 줄이는 것**이 비용 효율적이다.

**MySQL 튜닝 포인트**:

| 설정 | 기본값 | 권장값 | 효과 |
|------|--------|--------|------|
| `innodb_buffer_pool_size` | 128MB | 서버 메모리의 50~70% | 디스크 I/O 감소 |
| `innodb_log_file_size` | 48MB | 256MB~1GB | 쓰기 성능 향상 |
| `innodb_flush_log_at_trx_commit` | 1 | 2 | 쓰기 성능 향상 (약간의 내구성 트레이드오프) |
| `max_connections` | 151 | 50~100 | 과도한 커넥션 방지 |
| `innodb_deadlock_detect` | ON | ON (유지) | 데드락 자동 감지 + 롤백 |

---

### 3.2 동시성 제어: 비관적 락 유지 + Named Lock 병행

**단일 서버에서는 JPA 비관적 락이 여전히 유효하다.** 분산 락(Redis)은 다중 서버 환경을 위한 것이므로 단일 서버에서는 오버스펙이다.

**현재 방식 유지**:

```java
@Lock(LockModeType.PESSIMISTIC_WRITE)
@Query("SELECT c FROM Course c WHERE c.id = :id")
Optional<Course> findByIdWithLock(@Param("id") Long id);
```

**Named Lock 병행 (MySQL 전환 시 추가 가능)**:

Named Lock은 행 자체를 잠그지 않으므로 조회 쿼리에 영향을 주지 않는다. 비관적 락의 "락 대기 중 커넥션 점유" 문제를 완화할 수 있다.

```java
// 별도 커넥션으로 Named Lock 획득
GET_LOCK('course_enroll_42', 3)  // course_id=42에 대해 3초 대기

// 비즈니스 로직 수행 (별도 커넥션)
→ 정원 확인 → 수강신청 → enrolled 증가

// Named Lock 해제
RELEASE_LOCK('course_enroll_42')
```

**Named Lock 사용 시 주의점**:
- Named Lock용 커넥션과 비즈니스 로직용 커넥션을 **분리**해야 한다
- Named Lock 커넥션이 트랜잭션에 묶이면 락 해제가 지연될 수 있다
- HikariCP DataSource를 2개 설정 (메인용 + Named Lock용)

**트레이드오프**:

| 전략 | 조회 영향 | 커넥션 점유 | 구현 복잡도 | 단일 서버 적합도 |
|------|:-------:|:--------:|:--------:|:------------:|
| 비관적 락 (현재) | 있음 | 락 대기 중 점유 | 낮음 | 적합 |
| 비관적 락 + Named Lock | 없음 | 분리 가능 | 중간 | 매우 적합 |

---

### 3.3 캐싱: Write-Through 전략 (Caffeine Local Cache)

**현재**: 모든 요청이 DB를 직접 조회한다.

**단일 서버에서는 Local Cache가 최적이다.** Redis 같은 외부 캐시는 네트워크 왕복 비용이 추가되지만, Caffeine은 같은 프로세스 내 메모리에서 조회하므로 지연이 0에 가깝다.

**수강신청 도메인에 최적화된 Write-Through 전략**:

수강신청은 **정원이 단방향으로 차는 구조**다:

```
정원 40 → 39 → 38 → ... → 1 → 0 (마감)
         ↑ 이 구간만 쓰기 발생       ↑ 이후 100% 캐시 히트
```

- 쓰기는 최대 정원 수만큼만 발생하고, 마감 후에는 모든 조회가 캐시에서 처리된다
- 스파이크 구간에서 취소는 거의 발생하지 않는다
- 인기 강좌일수록 빨리 마감되어, 빨리 캐시 히트율 100%에 도달한다

**동작 흐름**:

```
[GET /courses 조회]
  → Caffeine 캐시 존재? → 캐시 반환 (DB 안 감)
  → 캐시 없음? → DB 조회 → 캐시 저장 → 반환

[POST /enrollments 수강신청]
  → DB 비관적 락 → 비즈니스 검증 → enrolled 증가 → DB 커밋
  → Caffeine 캐시에 해당 강좌의 enrolled 값 즉시 갱신 (write-through)

[DELETE /enrollments 수강취소]
  → DB 처리 → enrolled 감소
  → Caffeine 캐시에 해당 강좌의 enrolled 값 즉시 갱신
```

**캐시 히트율 시뮬레이션**:

| 시나리오 | 정원 | 조회 요청 수 | 캐시 히트율 |
|----------|:----:|:----------:|:--------:|
| 인기 강좌 | 30명 | 5,000건 | 99.4% |
| 일반 강좌 | 40명 | 1,000건 | 96% |
| 비인기 강좌 | 50명 | 100건 | 50% (하지만 조회 자체가 적어 DB 부하 미미) |

**TTL 기반 캐싱 대비 장점**:

| 항목 | TTL 기반 캐싱 | Write-Through 캐싱 |
|------|:-----------:|:-----------------:|
| stale 데이터 | TTL 만료 전까지 발생 | 없음 (매 쓰기마다 갱신) |
| 잔여 정원 정확도 | TTL에 따라 부정확 | 항상 정확 |
| 캐시 무효화 복잡도 | TTL 설정 고민 필요 | 단순 (등록/취소 시 갱신) |

**대상별 캐시 정책**:

| 데이터 | 캐시 방식 | 이유 |
|--------|----------|------|
| 강좌 목록 + 잔여 정원 | Write-Through | 수강신청/취소 시 즉시 갱신 |
| 학과 목록 | TTL 10분 | 학기 중 변경 없음 |
| 교수 목록 | TTL 10분 | 학기 중 변경 없음 |

---

### 3.4 인증/인가: 없음 → JWT + Spring Security

**현재**: `studentId`를 요청 파라미터로 직접 전달. 누구나 아무 학생으로 수강신청 가능.

**프로덕션 구성**:

```
로그인 → JWT 발급 (Access Token 15분 + Refresh Token 7일)
       → Access Token에 studentId, 학년, 학과 포함
       → API 요청 시 Authorization 헤더에 Access Token 전달
       → Spring Security Filter에서 자동 검증
```

| 항목 | 설정 |
|------|------|
| Access Token 수명 | 15분 |
| Refresh Token 수명 | 7일 |
| Refresh Token 저장 | Redis (단일 인스턴스) 또는 DB |
| 토큰 폐기 | Redis 블랙리스트 또는 DB 테이블 |
| 비밀번호 해싱 | BCrypt |
| 수강신청 API | 토큰에서 studentId 추출 (파라미터 제거) |

단일 서버이므로 세션 기반 인증도 가능하지만, JWT를 선택하는 이유는 서버 메모리에 세션을 저장하지 않아 수강신청 스파이크 시 메모리 부담을 줄일 수 있기 때문이다.

---

### 3.5 트래픽 제어: Nginx + 정적 대기열 페이지

다중 서버 없이도 트래픽 유입 속도를 제어할 수 있다. **Nginx 리버스 프록시**가 핵심이다.

**Nginx의 역할**:

```
사용자 → Nginx (:80/443)
          ├── 정적 자산 직접 서빙 (Spring Boot 부하 제거)
          ├── Rate Limiting (IP당 요청 제한)
          ├── 동시 접속 제한 (limit_conn)
          ├── 대기열 페이지 반환 (503 시 정적 HTML)
          └── → Spring Boot (:8080) (API 요청만 프록시)
```

**Nginx Rate Limiting 설정**:

```nginx
# IP당 초당 10개 요청 허용, 초과 시 대기열 20개
limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;

# 동시 접속 제한
limit_conn_zone $binary_remote_addr zone=conn:10m;

location /api/ {
    limit_req zone=api burst=20 nodelay;
    limit_conn conn 5;           # IP당 동시 연결 5개
    proxy_pass http://127.0.0.1:8080;
}

# 서버 과부하 시 정적 대기 페이지 반환
error_page 503 /waiting.html;
location = /waiting.html {
    root /var/www/static;
    internal;
}
```

**대기열 페이지 전략**:

대규모 가상 대기실(Redis ZSET) 없이도 효과적인 대기 경험을 제공할 수 있다:

```
1. Nginx가 동시 처리량 초과 요청에 503 반환
2. 정적 대기 HTML 페이지 표시 ("잠시 후 다시 시도해주세요")
3. 페이지 내 JavaScript가 3~5초 간격으로 자동 재요청
4. 서버 여유가 생기면 요청 통과
```

이 방식은 Redis 기반 대기열 대비 정교하지 않지만, **추가 인프라 없이 Nginx만으로 구현** 가능하고, 서버가 처리할 수 있는 만큼만 요청을 받아들이므로 과부하를 확실히 방지한다.

---

### 3.6 Rate Limiting (애플리케이션 레벨)

Nginx의 IP 기반 제한에 더해, 애플리케이션 레벨에서 사용자별 제한을 건다.

**현재**: 제한 없음. 한 사용자가 무한 요청 가능.

**프로덕션 (Resilience4j)**:

| 대상 | 제한 | 이유 |
|------|------|------|
| 수강신청 API | 사용자당 2초에 1회 | 클릭 스팸 방지 |
| 강좌 조회 API | 사용자당 초당 5회 | 과도한 새로고침 방지 |

Resilience4j는 Spring Boot에 의존성만 추가하면 되고, 별도 인프라가 필요 없다.

---

### 3.7 Circuit Breaker: DB 과부하 시 빠른 실패

**현재**: DB 과부하 시 모든 요청이 타임아웃까지 대기 → 전체 서비스 마비.

**프로덕션 (Resilience4j)**:

```
Closed (정상) → 실패율 50% 초과 → Open (차단, 즉시 실패 응답)
    → 30초 대기 → Half-Open (3건 시험 요청)
    → 성공 시 Closed 복귀 / 실패 시 Open 유지
```

| 설정 | 값 |
|------|-----|
| failureRateThreshold | 50% |
| slowCallDurationThreshold | 2초 |
| slidingWindowSize | 10 |
| waitDurationInOpenState | 30초 |

DB가 과부하 상태일 때 Circuit Breaker가 열려 빠르게 "시스템이 혼잡합니다" 응답을 반환한다. DB가 회복될 시간을 확보하고, 사용자는 30초 타임아웃 대신 즉시 재시도 가능 여부를 알 수 있다.

**단일 서버에서 특히 중요한 이유**: 서버가 1대뿐이므로 DB 과부하가 곧 전체 서비스 마비다. Circuit Breaker가 없으면 모든 스레드가 DB 응답을 기다리며 블로킹되어 서버가 완전히 멈춘다.

---

### 3.8 커넥션 풀 최적화

**현재**: HikariCP 기본값 (max 10).

**프로덕션 공식** (HikariCP 공식 위키):

```
connections = (CPU 코어 수 × 2) + 유효 디스크 수
```

| 환경 | 계산 | 설정 |
|------|------|------|
| 4코어 서버 + SSD | (4 × 2) + 1 = 9 | maximumPoolSize = 9 |
| 8코어 서버 + SSD | (8 × 2) + 1 = 17 | maximumPoolSize = 17 |

> Oracle 실증 테스트에서 커넥션 풀을 적정 크기로 설정한 경우와 과도하게 설정한 경우 **50배 성능 차이**가 발생했다. 과도한 커넥션은 컨텍스트 스위칭을 유발하여 오히려 처리량을 떨어뜨린다.

**추가 설정**:

| 항목 | 기본값 | 프로덕션 권장 |
|------|--------|-------------|
| connectionTimeout | 30초 | 5~10초 (빠른 실패) |
| idleTimeout | 10분 | 10분 (유지) |
| maxLifetime | 30분 | MySQL wait_timeout보다 수 초 짧게 |

---

### 3.9 모니터링

**현재**: 없음. 장애 발생 시 로그를 직접 확인해야 한다.

**단일 서버에 적합한 경량 모니터링**:

| 도구 | 역할 | 비용 |
|------|------|------|
| **Spring Actuator** | 헬스체크, 메트릭 노출 (`/actuator/prometheus`) | 무료 (의존성 추가) |
| **Prometheus** | 메트릭 수집 (같은 서버에서 실행 가능) | 무료 (경량) |
| **Grafana** | 대시보드 (같은 서버에서 실행 가능) | 무료 (경량) |

ELK Stack이나 Jaeger 같은 무거운 도구는 단일 서버에 부담이 된다. Prometheus + Grafana는 같은 서버에서도 가볍게 실행 가능하며, 수강신청 기간에만 집중적으로 모니터링하면 된다.

**핵심 모니터링 지표**:

| 지표 | 임계값 | 알림 |
|------|--------|------|
| 수강신청 TPS | > 1,000 | 경고 |
| 응답 시간 P99 | > 3초 | 경고 |
| 에러율 | > 5% | 긴급 |
| DB 커넥션 사용률 | > 80% | 경고 |
| JVM 힙 메모리 사용률 | > 80% | 경고 |
| Nginx 503 응답 비율 | > 30% | 경고 |

---

### 3.10 JVM 튜닝

단일 서버의 성능을 극대화하려면 JVM 레벨 최적화도 필요하다.

| 설정 | 권장값 | 효과 |
|------|--------|------|
| `-Xms` / `-Xmx` | 서버 메모리의 50~60% | GC 빈도 감소, 안정적 힙 확보 |
| `-XX:+UseG1GC` | G1 GC 사용 | 대용량 힙에서 짧은 GC 일시정지 |
| `-XX:MaxGCPauseMillis` | 200ms | GC 일시정지 목표 시간 |

수강신청 스파이크 시 대량의 요청 객체가 생성되므로, GC 튜닝이 응답 시간에 직접적인 영향을 준다. G1 GC는 큰 힙에서도 일시정지 시간을 예측 가능하게 유지해준다.

---

## 4. 인프라 아키텍처 비교

### 현재 (과제)

```
[사용자] → [Spring Boot :8080] → [H2 In-Memory]
```

- 서버 1대, DB 내장, 인프라 없음
- 장점: 즉시 실행, 설치 불필요
- 한계: 단일 장애점(SPOF), 데이터 휘발, 트래픽 제어 없음

### 프로덕션 (단일 서버 최적화)

```
[사용자]
   │
[Nginx] (:80/443)
   ├── 정적 자산 직접 서빙
   ├── Rate Limiting (IP당 제한)
   ├── 동시 접속 제한
   ├── 과부하 시 대기열 페이지 반환
   │
   └── [Spring Boot] (:8080)
           ├── Spring Security + JWT (인증)
           ├── Caffeine (Write-Through Local Cache)
           ├── Resilience4j (Circuit Breaker + Rate Limiter)
           ├── HikariCP (최적화된 Connection Pool)
           │
           └── [MySQL 8.0] (단일 인스턴스)
                   ├── InnoDB 버퍼 풀 최적화
                   ├── 비관적 락 + Named Lock
                   └── 일일 백업

[같은 서버 또는 별도 경량 서버]
   └── Prometheus + Grafana (모니터링)
```

**추가 인프라 비용: Nginx (무료) + MySQL (무료) + Prometheus/Grafana (무료)**

---

## 5. 단계별 전환 로드맵

### Phase 1: 기반 전환 (필수)

| 작업 | 변경 내용 | 기대 효과 |
|------|----------|----------|
| DB 전환 | H2 → MySQL | 데이터 영속성, Named Lock, 데드락 감지 |
| 인증 도입 | Spring Security + JWT | 보안 확보, 사용자 식별 |
| 커넥션 풀 튜닝 | HikariCP 설정 최적화 | 커넥션 효율 극대화 |
| Nginx 도입 | 리버스 프록시 + 정적 자산 분리 | Spring Boot 부하 감소 |

### Phase 2: 성능 최적화

| 작업 | 변경 내용 | 기대 효과 |
|------|----------|----------|
| Write-Through 캐싱 | Caffeine Local Cache | DB 조회 부하 90%+ 감소 |
| Rate Limiting | Nginx + Resilience4j | 서버 보호, 악용 방지 |
| Circuit Breaker | Resilience4j | DB 과부하 시 빠른 실패 |
| 대기열 페이지 | Nginx 503 → 정적 대기 HTML | 과부하 시 사용자 경험 개선 |

### Phase 3: 안정화

| 작업 | 변경 내용 | 기대 효과 |
|------|----------|----------|
| 모니터링 | Actuator + Prometheus + Grafana | 장애 감지, 성능 분석 |
| JVM 튜닝 | G1 GC, 힙 크기 최적화 | GC 일시정지 최소화 |
| MySQL 튜닝 | InnoDB 버퍼 풀, 로그 파일 크기 | DB 성능 최적화 |
| 부하 테스트 | nGrinder | 병목 사전 발견, 임계치 확인 |
| DB 백업 | 일일 자동 백업 (cron + mysqldump) | 데이터 안전성 확보 |

### Phase 4 (선택): 단일 서버 한계 도달 시

단일 서버로 감당이 안 되는 규모(재학생 30,000명+, 동시 접속 10,000명+)라면 그때 확장을 검토한다:

| 작업 | 변경 내용 | 기대 효과 |
|------|----------|----------|
| Redis 도입 | 대기열 + 세션 + 캐시 | 정교한 대기열, 세션 외부화 |
| Read Replica | MySQL 복제 | 읽기 부하 분리 |
| 서버 추가 | 2대 구성 + L4/L7 LB | 처리량 2배 |

---

## 6. 목표 성능 지표

| 지표 | 현재 (과제) | 프로덕션 (단일 서버) |
|------|:---------:|:------------------:|
| 동시 접속자 | 100명 (테스트) | 1,000~3,000명 |
| 수강신청 TPS | ~100 | 500~2,000 |
| 강좌 조회 응답 시간 | 수 ms (H2) | < 10ms (캐시 히트 시) |
| 수강신청 응답 시간 | 수 ms | < 500ms |
| 가용률 | - | 99.5%+ |
| 데이터 영속성 | 없음 (인메모리) | 보장 (일일 백업) |

> 학년별 시차 배정(5,000명 → 1,000~2,000명)을 병행하면 단일 서버로 충분히 대응 가능한 수준이다.

---

## 7. 참고: 대학교 vs 기업 아키텍처 비교

| 항목 | 대학교 수강신청 | IT 기업 (쿠팡, 토스 등) |
|------|:------------:|:--------------------:|
| 트래픽 패턴 | 학기 2~3회 스파이크 | 상시 대규모 트래픽 |
| 피크 지속 시간 | 3~10분 | 24시간 |
| 예산 | 제한적 | 인프라 투자 가능 |
| 운영 인력 | 전산팀 (소수) | DevOps 전담팀 |
| **적합한 전략** | **단일 서버 최적화 + 트래픽 유입 제어** | **MSA + 분산 시스템 + 오토 스케일링** |

IT 기업들의 아키텍처(쿠팡의 MSA, 토스의 Active-Active DC, 배민의 CQRS)는 **상시 대규모 트래픽**을 처리하기 위한 것이다. 대학교처럼 연간 1시간도 안 되는 피크에 이런 인프라를 상시 운영하는 것은 비용 대비 효과가 맞지 않는다.

대신 대학교에서는:
1. **단일 서버의 성능을 극한까지 최적화** (캐싱, 커넥션 풀, JVM, DB 튜닝)
2. **트래픽 유입을 제어** (Nginx Rate Limiting, 대기열 페이지, 학년별 시차 배정)
3. **장애에 빠르게 대응** (Circuit Breaker, 모니터링)

이 세 가지 조합으로 현실적인 비용 내에서 안정적인 서비스를 제공할 수 있다.
